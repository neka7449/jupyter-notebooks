{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.5.3 :: Anaconda 4.4.0 (64-bit)\r\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name,tags\r\n",
      "train_0,haze primary\r\n",
      "train_1,agriculture clear primary water\r\n",
      "train_2,clear primary\r\n",
      "train_3,clear primary\r\n",
      "train_4,agriculture clear habitation primary road\r\n",
      "train_5,haze primary water\r\n",
      "train_6,agriculture clear cultivation primary water\r\n",
      "train_7,haze primary\r\n",
      "train_8,agriculture clear cultivation primary\r\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = \"./results/session-01-KagglePlanetAmazon/\"\n",
    "DATA_DIR = \"../../Data/kaggle-planet-amazon/\"\n",
    "\n",
    "!head ../../Data/kaggle-planet-amazon/train_v2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATA_DIR + \"train_v2.csv\")\n",
    "\n",
    "# df_train[\"tags\"] = df_train[\"tags\"].map(lambda x: x.split(\" \"))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# binarizedLabels_df = pd.DataFrame(binarizedLabels)\n",
    "# binarizedLabels_df.columns = mlb.classes_\n",
    "# binarizedLabels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "# from sklearn.metrics import matthews_corrcoef, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_valid_samples = df_train.sample(frac=0.2)\n",
    "\n",
    "df_train_samples = df_train.drop(df_valid_samples.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PrintShape(df, df_shape):\n",
    "    print(\"{} shape: {}\".format(df, df_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_samples shape: (32383, 2)\n",
      "df_valid_samples shape: (8096, 2)\n"
     ]
    }
   ],
   "source": [
    "PrintShape('df_train_samples', df_train_samples.shape)\n",
    "PrintShape('df_valid_samples', df_valid_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# mlb = MultiLabelBinarizer()\n",
    "\n",
    "# y_train = mlb.fit_transform(df_train_samples[\"tags\"])\n",
    "# y_valid = mlb.fit_transform(df_valid_samples[\"tags\"])\n",
    "\n",
    "# mlb.classes_\n",
    "\n",
    "####################################\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "input_size = 64\n",
    "input_channels = 3\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "lr_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8096/8096 [00:11<00:00, 704.13it/s]\n"
     ]
    }
   ],
   "source": [
    "x_valid = []\n",
    "y_valid = []\n",
    "\n",
    "for f, tags in tqdm(df_valid_samples.values, miniters=1000):\n",
    "    img = cv2.resize(cv2.imread(DATA_DIR + 'train-jpg/{}.jpg'.format(f)), (input_size, input_size))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1\n",
    "    x_valid.append(img)\n",
    "    y_valid.append(targets)\n",
    "\n",
    "y_valid = np.array(y_valid, np.uint8)\n",
    "x_valid = np.array(x_valid, np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32383/32383 [00:46<00:00, 696.68it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for f, tags in tqdm(df_train_samples.values, miniters=1000):\n",
    "    img = cv2.resize(cv2.imread(DATA_DIR + 'train-jpg/{}.jpg'.format(f)), (input_size, input_size))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1\n",
    "    x_train.append(img)\n",
    "    y_train.append(targets)\n",
    "    img = cv2.flip(img, 0)  # flip vertically\n",
    "    x_train.append(img)\n",
    "    y_train.append(targets)\n",
    "    img = cv2.flip(img, 1)  # flip horizontally\n",
    "    x_train.append(img)\n",
    "    y_train.append(targets)\n",
    "    img = cv2.flip(img, 0)  # flip vertically\n",
    "    x_train.append(img)\n",
    "    y_train.append(targets)\n",
    "\n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_samples = pd.read_csv(DATA_DIR + 'sample_submission_v2.csv')\n",
    "\n",
    "x_test = []\n",
    "\n",
    "for f, tags in tqdm(df_test_samples.values, miniters=1000):\n",
    "    img = cv2.resize(cv2.imread(DATA_DIR + 'test-jpg/{}.jpg'.format(f)), (input_size, input_size))\n",
    "    x_test.append(img)\n",
    "\n",
    "x_test = np.array(x_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(input_size, input_size, input_channels)))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, kernel_size=(2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "model.add(Conv2D(256, kernel_size=(2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(17, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 129532 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      "132s - loss: 0.0959 - acc: 0.9626 - val_loss: 0.0991 - val_acc: 0.9624\n",
      "Epoch 2/5\n",
      "132s - loss: 0.0947 - acc: 0.9630 - val_loss: 0.0989 - val_acc: 0.9623\n",
      "Epoch 3/5\n",
      "132s - loss: 0.0947 - acc: 0.9629 - val_loss: 0.0987 - val_acc: 0.9624\n",
      "Epoch 4/5\n",
      "132s - loss: 0.0943 - acc: 0.9631 - val_loss: 0.0987 - val_acc: 0.9626\n",
      "Epoch 5/5\n",
      "132s - loss: 0.0943 - acc: 0.9632 - val_loss: 0.0985 - val_acc: 0.9625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f43e040e7b8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           verbose=0),\n",
    "             TensorBoard(log_dir='logs'),\n",
    "             ModelCheckpoint('weights.h5',\n",
    "                             save_best_only=True)]\n",
    "\n",
    "opt = SGD(lr=learning_rate, decay=lr_decay)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=2,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00],\n",
       "       ..., \n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   2.15975014e-38,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   2.16432707e-16,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test = model.predict(x_test, batch_size=batch_size, verbose=2)\n",
    "p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.48763251e-01,   3.62713990e-07,   4.81881499e-02, ...,\n",
       "          1.21221016e-03,   3.06543522e-02,   2.27194298e-02],\n",
       "       [  9.98519242e-01,   2.53973074e-08,   1.91464320e-01, ...,\n",
       "          9.36937460e-04,   5.72787889e-04,   2.39368752e-01],\n",
       "       [  9.29065228e-01,   3.65488347e-07,   3.50466296e-02, ...,\n",
       "          1.91347708e-03,   1.71075203e-02,   1.36643827e-01],\n",
       "       ..., \n",
       "       [  9.99210000e-01,   1.94678961e-07,   1.15636771e-03, ...,\n",
       "          8.74504403e-05,   1.98195718e-04,   3.99420183e-04],\n",
       "       [  9.87671256e-01,   1.01347553e-06,   1.45826861e-01, ...,\n",
       "          3.86267719e-11,   2.61703860e-02,   1.15703970e-01],\n",
       "       [  2.44156674e-01,   4.11014116e-06,   8.98726523e-01, ...,\n",
       "          1.20391305e-05,   2.92568523e-02,   6.83853745e-01]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_valid = model.predict(x_valid, batch_size=batch_size)\n",
    "p_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/src/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:516: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(var_yt * var_yp)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "threshold = np.arange(0.1,0.9,0.1)\n",
    "\n",
    "acc = []\n",
    "accuracies = []\n",
    "best_threshold = np.zeros(p_valid.shape[1])\n",
    "for i in range(p_valid.shape[1]):\n",
    "    y_prob = np.array(p_valid[:,i])\n",
    "    for j in threshold:\n",
    "        y_pred = [1 if prob>=j else 0 for prob in y_prob]\n",
    "        acc.append(matthews_corrcoef(y_valid[:,i],y_pred))\n",
    "    acc   = np.array(acc)\n",
    "    index = np.where(acc==acc.max()) \n",
    "    accuracies.append(acc.max()) \n",
    "    best_threshold[i] = threshold[index[0][0]]\n",
    "    acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6,  0.4,  0.4,  0.2,  0.7,  0.4,  0.4,  0.4,  0.3,  0.1,  0.1,\n",
       "        0.1,  0.4,  0.4,  0.1,  0.4,  0.3])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([[1 if p_test[i,j]>=best_threshold[j] else 0 for j in range(p_test.shape[1])] for i in range(p_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_samples['tags'] = preds\n",
    "df_test_samples.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912979763217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61191 [00:00<?, ?it/s]/home/ec2-user/src/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "100%|██████████| 61191/61191 [02:20<00:00, 434.26it/s]\n"
     ]
    }
   ],
   "source": [
    "p_valid = model.predict(x_valid, batch_size=batch_size)\n",
    "print(fbeta_score(y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))\n",
    "\n",
    "y_test = []\n",
    "\n",
    "p_test = model.predict(x_test, batch_size=batch_size, verbose=2)\n",
    "y_test.append(p_test)\n",
    "\n",
    "result = np.array(y_test[0])\n",
    "result = pd.DataFrame(result, columns=labels)\n",
    "\n",
    "preds = []\n",
    "\n",
    "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
    "    a = result.ix[[i]]\n",
    "    a = a.apply(lambda x: x > 0.2, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))\n",
    "\n",
    "df_test_samples['tags'] = preds\n",
    "df_test_samples.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0, 1, ..., 0, 0, 1],\n",
       "        [1, 0, 1, ..., 0, 0, 1],\n",
       "        [1, 0, 1, ..., 0, 0, 1],\n",
       "        ..., \n",
       "        [1, 0, 1, ..., 0, 0, 1],\n",
       "        [1, 0, 1, ..., 0, 0, 1],\n",
       "        [1, 0, 1, ..., 0, 0, 1]]], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.57251012e-01,   5.69853000e-07,   7.38344714e-02, ...,\n",
       "          1.95736997e-03,   3.50051522e-02,   3.10137104e-02],\n",
       "       [  9.97661829e-01,   1.51181823e-07,   2.23692968e-01, ...,\n",
       "          1.83197740e-03,   1.20442291e-03,   2.31709197e-01],\n",
       "       [  9.15061414e-01,   1.01860519e-06,   6.62967637e-02, ...,\n",
       "          3.15179559e-03,   2.58877594e-02,   1.98440790e-01],\n",
       "       ..., \n",
       "       [  9.99349296e-01,   1.47166531e-07,   1.02706894e-03, ...,\n",
       "          9.32745461e-05,   1.96420166e-04,   3.49653215e-04],\n",
       "       [  9.64141905e-01,   2.34278104e-06,   1.89054370e-01, ...,\n",
       "          6.42874226e-11,   8.95127803e-02,   7.64575526e-02],\n",
       "       [  2.79360592e-01,   1.29797681e-05,   8.60429287e-01, ...,\n",
       "          2.35701882e-05,   4.96082455e-02,   6.36332929e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/src/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:516: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(var_yt * var_yp)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "threshold = np.arange(0.1,0.9,0.1)\n",
    "\n",
    "acc = []\n",
    "accuracies = []\n",
    "best_threshold = np.zeros(p_valid.shape[1])\n",
    "for i in range(p_valid.shape[1]):\n",
    "    y_prob = np.array(p_valid[:,i])\n",
    "    for j in threshold:\n",
    "        y_pred = [1 if prob>=j else 0 for prob in y_prob]\n",
    "        acc.append(matthews_corrcoef(y_valid[:,i],y_pred))\n",
    "    acc   = np.array(acc)\n",
    "    index = np.where(acc==acc.max()) \n",
    "    accuracies.append(acc.max()) \n",
    "    best_threshold[i] = threshold[index[0][0]]\n",
    "    acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4,  0.3,  0.3,  0.2,  0.7,  0.4,  0.4,  0.5,  0.3,  0.3,  0.1,\n",
       "        0.3,  0.4,  0.4,  0.1,  0.6,  0.3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897999527315\n"
     ]
    }
   ],
   "source": [
    "print(fbeta_score(y_valid, np.array(p_valid) > 0.4, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61191"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8096 is out of bounds for axis 0 with size 8096",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-55e6793c1789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mbest_threshold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-55e6793c1789>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mbest_threshold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-55e6793c1789>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mbest_threshold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 8096 is out of bounds for axis 0 with size 8096"
     ]
    }
   ],
   "source": [
    "y_pred = np.array([[1 if p_valid[i,j]>=best_threshold[j] else 0 for j in range(y_valid.shape[1])] for i in range(len(y_test[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039692803999069985"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(y_valid,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_correctly_predicted = len([i for i in range(len(y_valid)) if (y_valid[i]==y_pred[i]).sum() == 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4952"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correctly_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8096, 64, 64, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.16600790513834"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total_correctly_predicted/ x_valid.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Current Mean F2-Score: 0.58"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
